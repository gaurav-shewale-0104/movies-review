{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11e99ba-4795-4ef6-8990-15ca88db70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44fef16a-2d44-4287-a8eb-2333b7b2cf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import glob\n",
    "\n",
    "folder_path = \"movie_reviews\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3dbf0af9-eaa4-40b4-a193-5c3a3ec2bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_review = \"movie_reviews\\\\\" + 'pos'\n",
    "\n",
    "pos_text_files = glob.glob(f\"{pos_review}\\\\*.txt\")\n",
    "# pos_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a431540a-9500-49ce-bbfc-a09726d33581",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_review = \"movie_reviews\\\\\" + 'neg'\n",
    "\n",
    "neg_text_files = glob.glob(f\"{neg_review}\\\\*.txt\")\n",
    "# neg_text_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc91b121-d9e4-4d47-82dd-b1ab712d7972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "review_list =[]\n",
    "\n",
    "for file_name in pos_text_files:\n",
    "    f = open(file_name)\n",
    "    text = f.read()\n",
    "    text = re.sub('[^A-Za-z]+',\" \",text)\n",
    "    f.close()\n",
    "    review_list.append(text)\n",
    "    \n",
    "\n",
    "for file_name in neg_text_files:\n",
    "    f = open(file_name)\n",
    "    text = f.read()\n",
    "    text = re.sub('[^A-Za-z]+',\" \",text)\n",
    "    f.close()\n",
    "    review_list.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017df39d-3a60-4948-b089-f0700943e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bcbbdce-6227-48fb-9904-beefc3c5263d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'every now and then a movie comes along from a suspect studio with every indication that it will be a stinker and to everybody s surprise perhaps even the studio the film becomes a critical darling mtv films election a high school comedy starring matthew broderick and reese witherspoon is a current example did anybody know this film existed a week before it opened the plot is deceptively simple george washington carver high school is having student elections tracy flick reese witherspoon is an over achiever with her hand raised at nearly every question way way high mr m matthew broderick sick of the megalomaniac student encourages paul a popular but slow jock to run and paul s nihilistic sister jumps in the race as well for personal reasons the dark side of such sleeper success is that because expectations were so low going in the fact that this was quality stuff made the reviews even more enthusiastic than they have any right to be you can t help going in with the baggage of glowing reviews which is in contrast to the negative baggage that the reviewers were likely to have election a good film does not live up to its hype what makes election so disappointing is that it contains significant plot details lifted directly from rushmore released a few months earlier the similarities are staggering tracy flick election is the president of an extraordinary number of clubs and is involved with the school play max fischer rushmore is the president of an extraordinary number of clubs and is involved with the school play the most significant tension of election is the potential relationship between a teacher and his student the most significant tension of rushmore is the potential relationship between a teacher and his student tracy flick is from a single parent home which has contributed to her drive max fischer is from a single parent home which has contributed to his drive the male bumbling adult in election matthew broderick pursues an extramarital affair gets caught and his whole life is ruined he even gets a bee sting the male bumbling adult in rushmore bill murray pursues an extramarital affair gets caught and his whole life is ruined he gets several bee stings and so on what happened how is it that an individual screenplay rushmore and a novel election contain so many significant plot points and yet both films were probably not even aware of each other made from two different studios from a genre the high school geeks revenge movie that hadn t been fully formed yet even so the strengths of election rely upon its fantastic performances from broderick witherspoon and newcomer jessica campbell as paul s anti social sister tammy broderick here is playing the mr rooney role from ferris bueller and he seems to be having the most fun he s had since then witherspoon is a revelation it s early in the year it s a comedy and teenagers have little clout but for my money witherspoon deserves an oscar nomination and once campbell s character gets going like in her fantastic speech in the gymnasium then you re won over one thing that s been bothering me since i ve seen it there is an extraordinary amount of sexuality in this film i suppose that coming from mtv films i should expect no less but the film starts off light and airy like a sitcom as the screws tighten and the tensions mount alexander payne decides to add elements that frankly distract from the story it is bad enough that mr m doesn t like tracy s determination to win at all costs but did they have to throw in the student teacher relationship even so there s no logical reason why mr m has an affair when he does there s a lot to like in election but the plot similarities to rushmore and the tonal nosedive it takes as it gets explicitly sex driven mark this as a disappointment '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7ee9e15-348f-42bd-a9ee-798c755183f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_target = np.ones(len(pos_text_files), dtype=int)\n",
    "neg_target = np.zeros(len(neg_text_files), dtype=int)\n",
    "pos_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a85fec6-c977-4c13-a540-82a00828c776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.append(pos_target,neg_target)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaf8b6f-8514-4fd9-971e-2b9342166bb5",
   "metadata": {},
   "source": [
    "## Bag of wards >> count vectorizer "
   ]
  },
  {
   "cell_type": "raw",
   "id": "d259cbff-3832-43bb-873c-8b926c35fed5",
   "metadata": {},
   "source": [
    "min_df = 0.05  >> It will igonre terms that appears in text less than 5%\n",
    "min_df = 40 >> It will igonre that appears less than 40 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0d994b2-1f8c-4767-b5e0-cdbc74440b22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words='english',min_df=0.03)\n",
    "X_count_vect = count_vect.fit_transform(review_list)\n",
    "X_count_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67ee6255-5242-46cb-8e62-be277a963f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academy</th>\n",
       "      <th>accent</th>\n",
       "      <th>accept</th>\n",
       "      <th>accident</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 1607 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ability  able  absolutely  academy  accent  accept  accident  act  \\\n",
       "0           0     0           0        0       2       0         0    0   \n",
       "1           0     0           0        0       0       0         0    0   \n",
       "2           0     0           1        0       0       0         0    0   \n",
       "3           0     0           0        1       0       0         0    5   \n",
       "4           0     0           0        0       0       0         0    0   \n",
       "...       ...   ...         ...      ...     ...     ...       ...  ...   \n",
       "1995        0     0           1        0       0       0         0    0   \n",
       "1996        1     0           0        0       0       0         0    0   \n",
       "1997        1     0           0        0       0       0         0    1   \n",
       "1998        0     0           0        0       0       0         0    0   \n",
       "1999        0     0           0        0       0       0         0    0   \n",
       "\n",
       "      acted  acting  ...  written  wrong  wrote  yeah  year  years  yes  york  \\\n",
       "0         0       1  ...        0      0      0     0     0      0    0     0   \n",
       "1         0       0  ...        0      0      0     0     1      0    0     0   \n",
       "2         0       1  ...        0      0      0     0     2      0    0     0   \n",
       "3         0       1  ...        0      0      0     0     0      1    0     1   \n",
       "4         0       0  ...        0      0      0     0     0      0    0     1   \n",
       "...     ...     ...  ...      ...    ...    ...   ...   ...    ...  ...   ...   \n",
       "1995      0       0  ...        0      0      0     0     2      0    1     0   \n",
       "1996      0       0  ...        0      0      0     0     1      1    0     0   \n",
       "1997      0       0  ...        0      0      0     0     0      0    0     0   \n",
       "1998      0       0  ...        1      1      0     0     0      0    0     0   \n",
       "1999      0       0  ...        0      0      0     0     0      0    0     0   \n",
       "\n",
       "      young  younger  \n",
       "0         0        0  \n",
       "1         0        0  \n",
       "2         0        0  \n",
       "3         1        0  \n",
       "4         0        0  \n",
       "...     ...      ...  \n",
       "1995      0        0  \n",
       "1996      0        0  \n",
       "1997      0        0  \n",
       "1998      0        0  \n",
       "1999      0        0  \n",
       "\n",
       "[2000 rows x 1607 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(X_count_vect.toarray(),columns = count_vect.get_feature_names())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d27d39d-b4d9-4b7f-9ee0-549ac468b7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ability', 'able', 'absolutely', 'academy', 'accent', 'accept', 'accident', 'act', 'acted', 'acting', 'action', 'actions', 'actor', 'actors', 'actress', 'acts', 'actual', 'actually', 'adaptation', 'add', 'added', 'addition', 'adds', 'admit', 'adult', 'adults', 'adventure', 'affair', 'age', 'agent', 'ago', 'ahead', 'air', 'alan', 'alien', 'aliens', 'alive', 'allen', 'allow', 'allowed', 'allows', 'amazing', 'america', 'american', 'amusing', 'angry', 'animal', 'animated', 'animation', 'annoying', 'answer', 'anti', 'apart', 'apartment', 'apparent', 'apparently', 'appeal', 'appealing', 'appear', 'appearance', 'appears', 'appreciate', 'approach', 'appropriate', 'aren', 'army', 'arrives', 'art', 'artist', 'aside', 'ask', 'asked', 'asking', 'asks', 'aspect', 'aspects', 'ass', 'assistant', 'atmosphere', 'attack', 'attempt', 'attempts', 'attention', 'attitude', 'attractive', 'audience', 'audiences', 'available', 'average', 'avoid', 'award', 'aware', 'away', 'awful', 'baby', 'background', 'bad', 'badly', 'band', 'bar', 'barely', 'based', 'basic', 'basically', 'batman', 'battle', 'beat', 'beautiful', 'beauty', 'began', 'begin', 'beginning', 'begins', 'believable', 'believe', 'believes', 'ben', 'best', 'better', 'big', 'bigger', 'biggest', 'billy', 'bit', 'bizarre', 'black', 'blame', 'bland', 'blood', 'bloody', 'blue', 'board', 'bob', 'body', 'bond', 'book', 'books', 'bored', 'boring', 'born', 'boss', 'bound', 'box', 'boy', 'boyfriend', 'boys', 'brain', 'break', 'breaking', 'breaks', 'brian', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'british', 'broken', 'brother', 'brothers', 'brought', 'brown', 'bruce', 'buddy', 'budget', 'build', 'building', 'built', 'bunch', 'business', 'buy', 'called', 'calls', 'came', 'cameo', 'camera', 'cameron', 'camp', 'capable', 'captain', 'car', 'care', 'career', 'cares', 'carry', 'cartoon', 'case', 'cash', 'cast', 'casting', 'catch', 'caught', 'cause', 'causes', 'center', 'central', 'century', 'certain', 'certainly', 'chance', 'change', 'changed', 'changes', 'character', 'characterization', 'characters', 'charm', 'charming', 'chase', 'cheap', 'check', 'cheesy', 'chemistry', 'chief', 'child', 'children', 'choice', 'chosen', 'chris', 'christopher', 'cinema', 'cinematic', 'cinematographer', 'cinematography', 'city', 'class', 'classic', 'clean', 'clear', 'clearly', 'clever', 'clich', 'cliched', 'cliches', 'climax', 'close', 'club', 'cold', 'college', 'color', 'come', 'comedic', 'comedies', 'comedy', 'comes', 'comic', 'coming', 'common', 'company', 'compared', 'comparison', 'compelling', 'complete', 'completely', 'complex', 'computer', 'concept', 'concerned', 'conclusion', 'conflict', 'confused', 'confusing', 'connection', 'consider', 'considered', 'considering', 'constant', 'constantly', 'contact', 'contains', 'content', 'continue', 'continues', 'contrived', 'control', 'convincing', 'cool', 'cop', 'cops', 'core', 'costumes', 'couldn', 'count', 'country', 'couple', 'course', 'cover', 'crap', 'crash', 'crazy', 'create', 'created', 'creates', 'creating', 'creative', 'credit', 'credits', 'creepy', 'crew', 'crime', 'criminal', 'critics', 'critique', 'cross', 'crowd', 'cult', 'culture', 'current', 'cut', 'cute', 'dad', 'damn', 'dance', 'dangerous', 'danny', 'dark', 'date', 'daughter', 'david', 'day', 'days', 'dead', 'deal', 'dealing', 'deals', 'death', 'debut', 'decade', 'decent', 'decide', 'decided', 'decides', 'decision', 'deep', 'definitely', 'deliver', 'delivers', 'dennis', 'depth', 'deserves', 'design', 'desire', 'desperate', 'desperately', 'despite', 'destroy', 'details', 'detective', 'determined', 'develop', 'developed', 'development', 'device', 'dialogue', 'did', 'didn', 'die', 'died', 'dies', 'difference', 'different', 'difficult', 'dimensional', 'direct', 'directed', 'directing', 'direction', 'directly', 'director', 'directors', 'disappointing', 'disappointment', 'disaster', 'discover', 'discovers', 'disney', 'disturbing', 'doctor', 'does', 'doesn', 'dog', 'doing', 'dollars', 'don', 'door', 'double', 'doubt', 'dr', 'drama', 'dramatic', 'draw', 'drawn', 'dream', 'dreams', 'drive', 'driven', 'driver', 'driving', 'drug', 'dull', 'dumb', 'dying', 'earlier', 'early', 'earth', 'easily', 'easy', 'eccentric', 'ed', 'eddie', 'edge', 'editing', 'edward', 'effect', 'effective', 'effects', 'effort', 'efforts', 'element', 'elements', 'emotion', 'emotional', 'emotionally', 'emotions', 'encounter', 'end', 'ended', 'ending', 'ends', 'energy', 'engaging', 'english', 'enjoy', 'enjoyable', 'enjoyed', 'enter', 'entertaining', 'entertainment', 'entire', 'entirely', 'epic', 'episode', 'equally', 'era', 'escape', 'especially', 'event', 'events', 'eventually', 'everybody', 'evidence', 'evil', 'ex', 'exactly', 'example', 'excellent', 'exception', 'exciting', 'excuse', 'exist', 'existence', 'expect', 'expectations', 'expected', 'expecting', 'experience', 'explain', 'explained', 'extra', 'extreme', 'extremely', 'eye', 'eyes', 'face', 'faced', 'faces', 'fact', 'fail', 'failed', 'fails', 'failure', 'fair', 'fairly', 'fake', 'fall', 'falling', 'falls', 'fame', 'familiar', 'family', 'famous', 'fan', 'fans', 'fantastic', 'fantasy', 'far', 'fare', 'fascinating', 'fashion', 'fast', 'fate', 'father', 'fault', 'favorite', 'fbi', 'fear', 'feature', 'features', 'featuring', 'feel', 'feeling', 'feelings', 'feels', 'feet', 'fellow', 'felt', 'female', 'fi', 'fiction', 'field', 'fight', 'fighting', 'fights', 'figure', 'figures', 'filled', 'film', 'filmed', 'filmmaker', 'filmmakers', 'filmmaking', 'films', 'final', 'finale', 'finally', 'finding', 'finds', 'fine', 'fit', 'flat', 'flaws', 'flick', 'flicks', 'floor', 'fly', 'flying', 'focus', 'folks', 'follow', 'followed', 'following', 'follows', 'food', 'foot', 'footage', 'force', 'forced', 'forces', 'forever', 'forget', 'forgotten', 'form', 'formula', 'forward', 'fox', 'frame', 'frank', 'free', 'french', 'frequently', 'fresh', 'friend', 'friends', 'frightening', 'fully', 'fun', 'funniest', 'funny', 'future', 'gags', 'game', 'gang', 'gary', 'gave', 'gay', 'general', 'generally', 'generated', 'generation', 'genius', 'genre', 'genuine', 'genuinely', 'george', 'gets', 'getting', 'giant', 'girl', 'girlfriend', 'girls', 'given', 'gives', 'giving', 'goal', 'god', 'goes', 'going', 'gold', 'gone', 'good', 'goofy', 'gore', 'got', 'gotten', 'government', 'grace', 'grand', 'graphic', 'great', 'greater', 'greatest', 'green', 'ground', 'group', 'grow', 'grown', 'grows', 'guess', 'guilty', 'gun', 'guns', 'guy', 'guys', 'hair', 'half', 'hand', 'hands', 'happen', 'happened', 'happening', 'happens', 'happy', 'hard', 'hardly', 'hasn', 'hate', 'haven', 'having', 'head', 'headed', 'heads', 'hear', 'heard', 'heart', 'hearted', 'heavily', 'heavy', 'held', 'hell', 'help', 'helps', 'hero', 'heroes', 'hey', 'hidden', 'high', 'highly', 'hilarious', 'history', 'hit', 'hits', 'hold', 'holds', 'hollywood', 'home', 'honest', 'hope', 'hopes', 'hoping', 'horrible', 'horror', 'hot', 'hotel', 'hour', 'hours', 'house', 'huge', 'human', 'humanity', 'humans', 'humor', 'humorous', 'hurt', 'husband', 'ice', 'idea', 'ideas', 'identity', 'ii', 'ill', 'image', 'images', 'imagination', 'imagine', 'immediately', 'impact', 'important', 'impossible', 'impression', 'impressive', 'include', 'included', 'includes', 'including', 'incredible', 'incredibly', 'individual', 'industry', 'inevitable', 'information', 'innocent', 'inside', 'inspired', 'instance', 'instead', 'intelligence', 'intelligent', 'intended', 'intense', 'interested', 'interesting', 'intriguing', 'introduced', 'involved', 'involves', 'involving', 'island', 'isn', 'issues', 'jack', 'jackie', 'jackson', 'jail', 'james', 'jason', 'jean', 'jennifer', 'jerry', 'jim', 'job', 'joe', 'john', 'join', 'joke', 'jokes', 'jones', 'journey', 'jr', 'jump', 'just', 'keeping', 'keeps', 'kept', 'kevin', 'key', 'kid', 'kids', 'kill', 'killed', 'killer', 'killing', 'kills', 'kind', 'king', 'kiss', 'knew', 'know', 'knowledge', 'known', 'knows', 'la', 'lack', 'lacking', 'lacks', 'lady', 'lame', 'land', 'language', 'large', 'late', 'later', 'latest', 'laugh', 'laughable', 'laughing', 'laughs', 'law', 'lawyer', 'lead', 'leader', 'leading', 'leads', 'learn', 'learned', 'learns', 'leave', 'leaves', 'leaving', 'led', 'lee', 'left', 'legend', 'length', 'let', 'lets', 'level', 'lies', 'life', 'light', 'likable', 'like', 'liked', 'likely', 'likes', 'limited', 'line', 'liners', 'lines', 'list', 'literally', 'little', 'live', 'lives', 'living', 'll', 'local', 'logic', 'long', 'longer', 'look', 'looked', 'looking', 'looks', 'lose', 'loses', 'lost', 'lot', 'lots', 'loud', 'love', 'loved', 'lover', 'loves', 'loving', 'low', 'luck', 'lucky', 'machine', 'mad', 'magic', 'main', 'mainly', 'major', 'make', 'makes', 'making', 'male', 'man', 'manage', 'managed', 'manages', 'manner', 'mark', 'marriage', 'married', 'martin', 'mary', 'master', 'masterpiece', 'match', 'material', 'matt', 'matter', 'matters', 'matthew', 'maybe', 'mean', 'meaning', 'means', 'meant', 'media', 'mediocre', 'meet', 'meeting', 'meets', 'member', 'members', 'memorable', 'men', 'mention', 'mentioned', 'merely', 'mess', 'message', 'michael', 'middle', 'mike', 'military', 'million', 'mind', 'minor', 'minute', 'minutes', 'miss', 'missed', 'missing', 'mission', 'mistake', 'mix', 'modern', 'moment', 'moments', 'money', 'monster', 'months', 'mood', 'moral', 'morning', 'mother', 'motion', 'mouth', 'moves', 'movie', 'movies', 'moving', 'mr', 'murder', 'music', 'musical', 'mysterious', 'mystery', 'naked', 'named', 'names', 'narrative', 'nasty', 'natural', 'naturally', 'nature', 'near', 'nearly', 'necessary', 'need', 'needed', 'needs', 'new', 'news', 'nice', 'nicely', 'nick', 'night', 'non', 'normal', 'note', 'notice', 'novel', 'nudity', 'number', 'numerous', 'obsessed', 'obvious', 'obviously', 'occasional', 'occasionally', 'odd', 'offensive', 'offer', 'offers', 'office', 'officer', 'oh', 'ok', 'okay', 'old', 'older', 'ones', 'open', 'opening', 'opens', 'opinion', 'opportunity', 'opposite', 'order', 'original', 'originally', 'oscar', 'outside', 'outstanding', 'overall', 'overly', 'owner', 'pace', 'paced', 'pacing', 'pain', 'pair', 'parents', 'park', 'parody', 'particular', 'particularly', 'partner', 'parts', 'party', 'pass', 'past', 'pathetic', 'paul', 'pay', 'people', 'perfect', 'perfectly', 'performance', 'performances', 'period', 'person', 'personal', 'personality', 'peter', 'pg', 'phone', 'physical', 'pick', 'picture', 'pictures', 'piece', 'pieces', 'place', 'placed', 'places', 'plain', 'plan', 'planet', 'plans', 'play', 'played', 'player', 'players', 'playing', 'plays', 'pleasure', 'plenty', 'plot', 'plus', 'point', 'pointless', 'points', 'police', 'political', 'poor', 'poorly', 'pop', 'popular', 'portrayal', 'portrayed', 'position', 'positive', 'possible', 'possibly', 'post', 'potential', 'power', 'powerful', 'predictable', 'premise', 'presence', 'present', 'presented', 'presents', 'president', 'press', 'pretty', 'previous', 'previously', 'price', 'prison', 'private', 'probably', 'problem', 'problems', 'process', 'produced', 'producer', 'producers', 'product', 'production', 'professional', 'project', 'promise', 'protagonist', 'prove', 'proves', 'provide', 'provided', 'provides', 'public', 'pull', 'pulled', 'pulp', 'pure', 'purpose', 'puts', 'putting', 'quality', 'queen', 'question', 'questions', 'quick', 'quickly', 'quiet', 'quite', 'race', 'radio', 'range', 'rare', 'rarely', 'rate', 'rated', 'rating', 'reach', 'read', 'reading', 'ready', 'real', 'realistic', 'reality', 'realize', 'realized', 'realizes', 'really', 'reason', 'reasons', 'recent', 'recently', 'recommend', 'red', 'regular', 'relationship', 'relationships', 'relatively', 'release', 'released', 'relief', 'remain', 'remains', 'remake', 'remarkable', 'remember', 'reminiscent', 'rent', 'rescue', 'respect', 'responsible', 'rest', 'result', 'results', 'return', 'returns', 'reveal', 'revenge', 'review', 'reviews', 'rich', 'richard', 'ride', 'ridiculous', 'right', 'rise', 'rival', 'road', 'rob', 'robert', 'robin', 'rock', 'roger', 'role', 'roles', 'roll', 'romance', 'romantic', 'room', 'routine', 'rules', 'run', 'running', 'runs', 'rush', 'russell', 'ryan', 'sad', 'sadly', 'safe', 'said', 'sam', 'satire', 'satisfying', 'save', 'saved', 'saving', 'saw', 'say', 'saying', 'says', 'scary', 'scene', 'scenes', 'school', 'sci', 'science', 'score', 'scott', 'scream', 'screen', 'screenplay', 'screenwriter', 'screenwriters', 'script', 'sean', 'search', 'season', 'seat', 'second', 'seconds', 'secret', 'security', 'seeing', 'seemingly', 'seen', 'sees', 'self', 'send', 'sense', 'sent', 'sequel', 'sequence', 'sequences', 'series', 'seriously', 'serve', 'serves', 'set', 'sets', 'setting', 'seven', 'sex', 'sexual', 'sexy', 'shallow', 'shame', 'share', 'sharp', 'sheer', 'ship', 'shock', 'shoot', 'shooting', 'short', 'shot', 'shots', 'shouldn', 'showing', 'shown', 'shows', 'sick', 'sight', 'sign', 'silly', 'similar', 'simple', 'simply', 'singer', 'single', 'sister', 'sit', 'sitting', 'situation', 'situations', 'skills', 'slightly', 'slow', 'slowly', 'small', 'smart', 'smile', 'smith', 'social', 'society', 'solid', 'somewhat', 'son', 'song', 'songs', 'soon', 'sorry', 'sort', 'soul', 'sound', 'sounds', 'soundtrack', 'south', 'space', 'speak', 'speaking', 'special', 'spectacular', 'speech', 'speed', 'spend', 'spends', 'spent', 'spirit', 'spot', 'stage', 'stand', 'standard', 'standing', 'stands', 'star', 'starring', 'stars', 'start', 'started', 'starts', 'state', 'states', 'station', 'stay', 'steal', 'step', 'stephen', 'steve', 'steven', 'stick', 'stone', 'stop', 'store', 'stories', 'story', 'storyline', 'straight', 'strange', 'street', 'streets', 'strength', 'strong', 'struggle', 'stuck', 'student', 'studio', 'study', 'stuff', 'stunning', 'stupid', 'style', 'sub', 'subject', 'subplot', 'substance', 'subtle', 'succeeds', 'success', 'successful', 'suddenly', 'suit', 'summer', 'super', 'superb', 'superior', 'support', 'supporting', 'suppose', 'supposed', 'supposedly', 'sure', 'surface', 'surprise', 'surprised', 'surprises', 'surprising', 'surprisingly', 'survive', 'suspect', 'suspense', 'sweet', 'sympathetic', 'synopsis', 'taken', 'takes', 'taking', 'tale', 'talent', 'talented', 'talents', 'talk', 'talking', 'target', 'task', 'taste', 'teacher', 'team', 'technical', 'teen', 'teenage', 'teenagers', 'television', 'tell', 'telling', 'tells', 'tension', 'terms', 'terrible', 'terrific', 'test', 'th', 'thankfully', 'thanks', 'theater', 'theaters', 'theme', 'themes', 'thing', 'things', 'think', 'thinking', 'thinks', 'thirty', 'thomas', 'thoroughly', 'thought', 'thriller', 'throw', 'thrown', 'tim', 'time', 'times', 'tired', 'title', 'today', 'told', 'tom', 'tone', 'tony', 'took', 'total', 'totally', 'touch', 'touching', 'tough', 'town', 'track', 'trailer', 'train', 'travel', 'treat', 'tried', 'tries', 'trip', 'trouble', 'true', 'truly', 'trust', 'truth', 'try', 'trying', 'turn', 'turned', 'turning', 'turns', 'tv', 'twice', 'twist', 'twists', 'type', 'typical', 'ugly', 'ultimate', 'ultimately', 'understand', 'unexpected', 'unfortunate', 'unfortunately', 'unfunny', 'unique', 'united', 'unless', 'unlike', 'unnecessary', 'ups', 'use', 'used', 'uses', 'using', 'usual', 'usually', 'utterly', 'value', 'van', 'various', 've', 'version', 'veteran', 'victim', 'victims', 'video', 'view', 'viewer', 'viewers', 'viewing', 'villain', 'violence', 'violent', 'virtually', 'visit', 'visual', 'visually', 'visuals', 'voice', 'wait', 'waiting', 'walk', 'walking', 'wall', 'want', 'wanted', 'wants', 'war', 'warm', 'wars', 'wasn', 'waste', 'wasted', 'watch', 'watched', 'watching', 'water', 'way', 'ways', 'weak', 'wedding', 'week', 'weeks', 'weird', 'welcome', 'went', 'weren', 'west', 'white', 'wide', 'wife', 'wild', 'william', 'williams', 'willing', 'win', 'window', 'winner', 'winning', 'wise', 'wish', 'wit', 'witness', 'witty', 'woman', 'women', 'won', 'wonder', 'wonderful', 'wonderfully', 'wondering', 'woody', 'word', 'words', 'work', 'worked', 'working', 'works', 'world', 'worse', 'worst', 'worth', 'worthy', 'wouldn', 'write', 'writer', 'writers', 'writing', 'written', 'wrong', 'wrote', 'yeah', 'year', 'years', 'yes', 'york', 'young', 'younger']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c5ed42-b999-4739-b570-fa1e8a04725c",
   "metadata": {},
   "source": [
    "# tf-idf Vectorizer"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8031919-3bc0-4b01-abaa-d3b32cf0d674",
   "metadata": {},
   "source": [
    "Tf >> term frequency \n",
    "\n",
    "TF = no of words in document / Number of total words in dopcument  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bfc91ba-4274-41a5-88b4-9d1f7b83dfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2000x886 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 213487 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(stop_words='english',min_df=0.05)\n",
    "x_tfidf_vect = tfidf_vect.fit_transform(review_list)\n",
    "x_tfidf_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b79daf2-0e69-4cc4-8f56-e9ac8b31b6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.10235647, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.10225682, 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tfidf_vect.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26df92ca-6742-4bed-a77e-e9e7b1329e8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>act</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>actual</th>\n",
       "      <th>...</th>\n",
       "      <th>writers</th>\n",
       "      <th>writing</th>\n",
       "      <th>written</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044504</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.102356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.128293</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.289285</td>\n",
       "      <td>0.042533</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063777</td>\n",
       "      <td>0.043447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054598</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080876</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051310</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.074700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043402</td>\n",
       "      <td>0.043500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.102257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07528</td>\n",
       "      <td>0.078095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ability  able  absolutely       act    acting  action     actor  \\\n",
       "0     0.000000   0.0    0.000000  0.000000  0.050373     0.0  0.000000   \n",
       "1     0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "2     0.000000   0.0    0.102356  0.000000  0.068145     0.0  0.000000   \n",
       "3     0.000000   0.0    0.000000  0.289285  0.042533     0.0  0.000000   \n",
       "4     0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "...        ...   ...         ...       ...       ...     ...       ...   \n",
       "1995  0.000000   0.0    0.051310  0.000000  0.000000     0.0  0.000000   \n",
       "1996  0.074700   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "1997  0.102257   0.0    0.000000  0.085858  0.000000     0.0  0.069705   \n",
       "1998  0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.070130   \n",
       "1999  0.000000   0.0    0.000000  0.000000  0.000000     0.0  0.000000   \n",
       "\n",
       "        actors  actress    actual  ...  writers  writing  written     wrong  \\\n",
       "0     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "2     0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "3     0.043055      0.0  0.069053  ...      0.0      0.0  0.00000  0.000000   \n",
       "4     0.054598      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "...        ...      ...       ...  ...      ...      ...      ...       ...   \n",
       "1995  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1996  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1997  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "1998  0.000000      0.0  0.000000  ...      0.0      0.0  0.07528  0.078095   \n",
       "1999  0.000000      0.0  0.000000  ...      0.0      0.0  0.00000  0.000000   \n",
       "\n",
       "      wrote      year     years       yes      york     young  \n",
       "0       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1       0.0  0.044504  0.000000  0.000000  0.000000  0.000000  \n",
       "2       0.0  0.128293  0.000000  0.000000  0.000000  0.000000  \n",
       "3       0.0  0.000000  0.040127  0.000000  0.063777  0.043447  \n",
       "4       0.0  0.000000  0.000000  0.000000  0.080876  0.000000  \n",
       "...     ...       ...       ...       ...       ...       ...  \n",
       "1995    0.0  0.064312  0.000000  0.047589  0.000000  0.000000  \n",
       "1996    0.0  0.043402  0.043500  0.000000  0.000000  0.000000  \n",
       "1997    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1998    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1999    0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[2000 rows x 886 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.DataFrame(x_tfidf_vect.toarray(), columns = tfidf_vect.get_feature_names())\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8992fe07-c64f-4b1e-8997-c272596a4fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc821b3-41a4-481f-8d04-783d8b9c91f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 886)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761d34a1-60f8-42ad-a91f-453168977b39",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "baa26067-e298-4583-bf29-7f057062c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test, y_train,y_test = train_test_split(x,y, test_size=0.25, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e5655c3-26e6-416b-a3e7-74ad5e685bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1500, 886), (500, 886), (1500,), (500,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape, y_train.shape,y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5367054a-ff75-4965-967c-471a7e47c427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9f15a9-416c-42d3-8b31-2e87c47d83c2",
   "metadata": {},
   "source": [
    "### Testing Data Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6b8c3a4-428f-4504-846a-33e935bf64bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[200  50]\n",
      " [ 63 187]]\n",
      "Accuracy Score = 0.774\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78       250\n",
      "           1       0.79      0.75      0.77       250\n",
      "\n",
      "    accuracy                           0.77       500\n",
      "   macro avg       0.77      0.77      0.77       500\n",
      "weighted avg       0.77      0.77      0.77       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test Data Evaluation \n",
    "y_pred = gnb.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25f2e7e-c8b3-4d07-bbe7-68144f878791",
   "metadata": {},
   "source": [
    "### Traininig Data Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db1bb625-bc64-4c3a-979a-b0d4d775efce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[648 102]\n",
      " [116 634]]\n",
      "Accuracy Score = 0.8546666666666667\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86       750\n",
      "           1       0.86      0.85      0.85       750\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training Data Evaluation \n",
    "y_pred = gnb.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_train,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822686b9-2bd9-4eeb-925a-8419b1029872",
   "metadata": {},
   "source": [
    "# multinominalNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "14c1cc73-4d3e-45c6-a21a-67f6b31674fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb= MultinomialNB()\n",
    "mnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "332cbe4d-939e-437a-beb6-5317d6bc51f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[209  41]\n",
      " [ 47 203]]\n",
      "Accuracy Score = 0.824\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83       250\n",
      "           1       0.83      0.81      0.82       250\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.82      0.82      0.82       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test Data Evaluation \n",
    "y_pred = mnb.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ec4674b-aa21-4a66-be1e-e273e73edce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[635 115]\n",
      " [113 637]]\n",
      "Accuracy Score = 0.848\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       750\n",
      "           1       0.85      0.85      0.85       750\n",
      "\n",
      "    accuracy                           0.85      1500\n",
      "   macro avg       0.85      0.85      0.85      1500\n",
      "weighted avg       0.85      0.85      0.85      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training Data Evaluation \n",
    "y_pred = mnb.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_train,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c19809-7e40-436f-a112-13f5fdc6d35c",
   "metadata": {},
   "source": [
    "# BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8574eac1-4a85-4969-9992-a3d5dfb88d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87e37faa-561c-41cd-b1dc-7943ebd14a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[218  32]\n",
      " [ 60 190]]\n",
      "Accuracy Score = 0.816\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.87      0.83       250\n",
      "           1       0.86      0.76      0.81       250\n",
      "\n",
      "    accuracy                           0.82       500\n",
      "   macro avg       0.82      0.82      0.82       500\n",
      "weighted avg       0.82      0.82      0.82       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Test Data Evaluation \n",
    "y_pred = bnb.predict(x_test)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_test,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1313160-34c2-4519-a7b1-209d2e515a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix=\n",
      "[[641 109]\n",
      " [157 593]]\n",
      "Accuracy Score = 0.8226666666666667\n",
      "classification Report = \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.85      0.83       750\n",
      "           1       0.84      0.79      0.82       750\n",
      "\n",
      "    accuracy                           0.82      1500\n",
      "   macro avg       0.82      0.82      0.82      1500\n",
      "weighted avg       0.82      0.82      0.82      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Training Data Evaluation \n",
    "y_pred = bnb.predict(x_train)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_train,y_pred)\n",
    "print(f\"Confusion Matrix=\\n{cnf_matrix}\")\n",
    "\n",
    "acc = accuracy_score(y_train,y_pred)\n",
    "print(f\"Accuracy Score = {acc}\")\n",
    "\n",
    "clf_report = classification_report(y_train,y_pred)\n",
    "print(f\"classification Report = \\n {clf_report}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4520856-789c-4dec-b96e-609cd48bd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = \"\"\"This is one of the best theatrical experiences I've had and I'm so happy someone has taken the practical route rather than throwing everyone into a green screen. I watched the first one many times and I can't believe this just topped it by a huge margin. Tom Cruise will be written as the most passionate filmmaker in history. I mean to put a whole cast in a bunch of f-18 jets and act in a jet as well as film yourself is a huge deal. If this movie does not cross a billion then there is something wrong with taste that people have these days. So called marvel fans. This is what you call a cinematic experience. Not some cropped cgi scenes.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c520374-bfd9-4b47-b461-36f38e6620cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is one of the best theatrical experiences I ve had and I m so happy someone has taken the practical route rather than throwing everyone into a green screen I watched the first one many times and I can t believe this just topped it by a huge margin Tom Cruise will be written as the most passionate filmmaker in history I mean to put a whole cast in a bunch of f jets and act in a jet as well as film yourself is a huge deal If this movie does not cross a billion then there is something wrong with taste that people have these days So called marvel fans This is what you call a cinematic experience Not some cropped cgi scenes']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.sub('[^A-Za-z]+',\" \",review1)\n",
    "\n",
    "text_list = text.split()\n",
    "text_list = [\" \".join(text_list)]\n",
    "text_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f1a8439-de82-4066-8ed9-d721decf6966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 886)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data_vector = tfidf_vect.transform(text_list)\n",
    "arr = user_data_vector.toarray()\n",
    "print(arr.shape)\n",
    "result = gnb.predict(arr)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "844eba3f-c5b3-4614-91a4-98bd93cc98ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "u1 = \"\"\"If you were a late teen or in your early twenties in the mid 1980's the world was very different. No computers, no mobile phones, no internet, no DVD's. We had cars though, and bikes, and we loved them, and we loved films too. The original Top Gun captured this moment in time perfectly, and gave us a thrilling ride like we had never seen before. The humour, the games, the bikes, the aircraft and my word, those flying scenes. We went back to the cinema to see it again and again, and spent the following decades quoting the movie. As time went on, it remained like a static snapshot in time to perfectly represent that magical point in our lives for so many of us.\n",
    "\n",
    "Now, 36 years later, we are a generation that has lost our parents, we've had our own children who have moved on themselves, and we now approach the end of our own careers and our young selves are gone forever.\n",
    "\n",
    "This film is the missing bookend to that whole generation. The original was there for the start of our young adult lives, and this new film now marks the end. It's magnificent.\n",
    "\n",
    "I'm 55, but yesterday, just for one last night, I was 19 again. Thank you.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90431b72-1629-4c6d-a0d2-16b17664521e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
